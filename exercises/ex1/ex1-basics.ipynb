{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67c5b916",
   "metadata": {},
   "source": [
    "# Exercise 1: Basic LeanIX AI Agent\n",
    "\n",
    "## Goal\n",
    "\n",
    "We want you to make yourself familiar with LeanIX and to learn how you can find information about Enterprise Applications of your company both in the LeanIX workspace as well as via an AI Agent based on MCP.\n",
    "\n",
    "## Context\n",
    "\n",
    "New LeanIX customers typically start their LeanIX journey with [Application Rationalization](https://www.leanix.net/en/wiki/apm/application-rationalization) use case. They assess their Enterprise applications in order to make sure they align with business goals. LeanIX offers two metrics for this: [Functional fit and technical fit](https://help.sap.com/docs/leanix/ea/application-portfolio-assessment-enrich-data?locale=en-US).\n",
    "\n",
    "- Functional fit: Does this tool do what the business needs it to do?\n",
    "- Technical fit: Can we run and support this tool effectively in our IT environment? \n",
    "\n",
    "During this exercise, we want to identify applications that fit our business goals best. \n",
    "\n",
    "We thus formulate the following question: \n",
    "\n",
    "**Which applications have a perfect functional fit and fully appropriate technical fit?**\n",
    "\n",
    "\n",
    "## Tasks\n",
    "\n",
    "Your task is to answer the above question: \n",
    "- first in LeanIX directly\n",
    "- later with an AI Agent via MCP\n",
    "\n",
    "We will go through these steps:\n",
    "\n",
    "1. Find the information in LeanIX\n",
    "1. Create LeanIX API token\n",
    "1. Use the token to connect to the LeanIX MCP Server\n",
    "1. Filter the MCP tools \n",
    "1. Connect to an LLM on AI Core\n",
    "1. Create an AI Agent\n",
    "\n",
    "**Let's get started!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9591bc",
   "metadata": {},
   "source": [
    "## Task 1.1: Find information in LeanIX\n",
    "\n",
    "In order to answer the above question in LeanIX, we will navigate to the workspace and use a pre-built report to find the applications that match the defined criteria.\n",
    "\n",
    "**ðŸš§ Your task:** Please follow these steps:\n",
    "\n",
    "1. Log in to your [LeanIX demo workspace](https://demo-eu-9.leanix.net/SAPTechED/)\n",
    "1. Navigate to Reports and select Application Portfolio report\n",
    "1. Clear the filters for lifecycle and quality seal\n",
    "1. Hover over the green bubble in the upper right corner\n",
    "1. Click on the green bubble in the upper right corner\n",
    "1. Click on \"Show in Inventory\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e916bc7",
   "metadata": {},
   "source": [
    "You should now see the list of your \"rock star\" applications - those who have the best possible functional and technical fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67584ec",
   "metadata": {},
   "source": [
    "### âœ… Solution\n",
    "<details>\n",
    "<summary>Click to expand solution</summary>\n",
    "\n",
    "![Screenshot portfolio report](../../images/portfolio-report.png)\n",
    "\n",
    "10 applications match these criteria\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c85928",
   "metadata": {},
   "source": [
    "## Task 1.2: Create LeanIX API token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b843657",
   "metadata": {},
   "source": [
    "In order for us to access the same information via MCP, we need to create an API token. \n",
    "\n",
    "**ðŸš§ Your task:** Please follow these steps:\n",
    "\n",
    "1. In LeanIX, click on the user initials in the upper right corner\n",
    "1. Select Administration\n",
    "1. Scroll down to the section \"Discovery and Integrations\" and select \"Technical Users\"\n",
    "1. Click on \"Create Technical User\" or \"New Technical User\"\n",
    "1. As a name type in `mcp` + your assigned user number in the session\n",
    "    - e.g., if your user number if \"001\" --> type \"mcp001\"\n",
    "1. For permission role select \"MEMBER\"\n",
    "1. Set the expiry date to the last day of the current month\n",
    "1. Hit Save \n",
    "1. **Copy the Access token!** - only then click OK\n",
    "1. Go back to VSCode and paste the access token to your [`.env` file](../../.env) and assign it to the environment variable `LEANIX_API_TOKEN`\n",
    "\n",
    "Your technical user configuration should look similar to this:\n",
    "\n",
    "![Technical user](../../images/technical-user.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03463bff",
   "metadata": {},
   "source": [
    "## Task 1.3: Connect to LeanIX MCP Server\n",
    "\n",
    "Let's connect to the LeanIX MCP Server. We will use the API token from the previous step. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfec190",
   "metadata": {},
   "source": [
    "#### Load API token\n",
    "\n",
    "Let's first load the API token from the environment.\n",
    "\n",
    "**ðŸš§ Your task:** Execute the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5b887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "LEANIX_API_TOKEN = os.getenv(\"LEANIX_API_TOKEN\")\n",
    "\n",
    "if LEANIX_API_TOKEN:\n",
    "    print(\"LEANIX_API_TOKEN loaded successfully.\")\n",
    "else:\n",
    "    print(\"Warning: LEANIX_API_TOKEN is not set or empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c670d8",
   "metadata": {},
   "source": [
    "You should see a message \"loaded successfully\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad9279b",
   "metadata": {},
   "source": [
    "#### Connect to MCP Server\n",
    "\n",
    "Now connect to the LeanIX MCP Server. The code below creates an MCP Client using the LangChain library to connect and get the tools. \n",
    "\n",
    "**ðŸš§ Your task:** Execute the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d8ebbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "\n",
    "lx_api_token_base64 = base64.b64encode(\n",
    "    f\"apitoken:{LEANIX_API_TOKEN}\".encode()\n",
    ").decode()\n",
    "\n",
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"LeanIX MCP Remote\": {\n",
    "            \"transport\": \"streamable_http\",\n",
    "            \"url\": \"https://demo-eu-2.leanix.net/services/mcp-server/v1/mcp\",\n",
    "            \"headers\": {\"Authorization\": f\"Basic {lx_api_token_base64}\"},\n",
    "        }\n",
    "        # Add more servers as needed\n",
    "    }\n",
    ")\n",
    "\n",
    "tools = await client.get_tools()\n",
    "\n",
    "tool_data = [{\n",
    "    'Name': tool.name,\n",
    "    'Description': tool.description\n",
    "} for tool in tools]\n",
    "\n",
    "# Create DataFrame from tool data\n",
    "df_tools = pd.DataFrame(tool_data)\n",
    "\n",
    "# Truncate Description column to 200 characters\n",
    "df_tools['Description'] = df_tools['Description'].apply(lambda x: x[:200] + ('...' if len(x) > 200 else ''))\n",
    "\n",
    "# Show all text in columns and align left for readability\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "styles = [\n",
    "    {\"selector\": \"th\", \"props\": [(\"text-align\", \"left\")]},\n",
    "    {\"selector\": \"td\", \"props\": [(\"text-align\", \"left\")]}\n",
    "]\n",
    "\n",
    "# Display the table\n",
    "display(HTML(df_tools.style.set_table_styles(styles).to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e906bea",
   "metadata": {},
   "source": [
    "You should now see a table with the tools available on the MCP Server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6b623f",
   "metadata": {},
   "source": [
    "*The code connects to the LeanIX MCP Server using an API token, retrieves a list of available tools, and displays them in a formatted table. It first encodes the API token in base64, sets up a client with the necessary headers, and asynchronously fetches the tools. The code then creates a pandas DataFrame from the tool data, truncates long descriptions for readability, and uses custom styles to left-align the table columns. Finally, it displays the styled table as HTML in the notebook for easy viewing.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad24529",
   "metadata": {},
   "source": [
    "## Task 1.4: Filter the MCP Tools\n",
    "\n",
    "It is good practice to do some client-side filtering of tools as too many tools can overwhelm an LLM. We will do very basic filtering based on keywords for the moment to demonstrate the principle. In a real production system, we would rather implement semantic search over tool descriptions like in [rag-mcp](https://github.com/fintools-ai/rag-mcp).\n",
    "\n",
    "**ðŸš§ Your task:** Execute the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61864373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first tool from the list for reference\n",
    "print(\"First tool details:\")\n",
    "print(tools[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d843d9",
   "metadata": {},
   "source": [
    "Now you know the format of the `tool` data structure. Use this knowledge to filter by tool description."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cdc8d7",
   "metadata": {},
   "source": [
    "**ðŸš§ Your task:**\n",
    "\n",
    "Create a list `filtered_tools` which contains only the tools that have the word \"application\" in their description. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba3bfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tools = [\n",
    "    # Your code here\n",
    "]\n",
    "\n",
    "print(f\"Filtered tools ({len(filtered_tools)}):\")\n",
    "for tool in filtered_tools:\n",
    "    print(f\"Tool: {tool.name}\")\n",
    "    print(tool.description)\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a93a5f",
   "metadata": {},
   "source": [
    "You should now see 3 tools in `filtered_tools`. The selection is not perfect but good enough for us to continue as the LLM will figure out the right tool to call later on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ac04b0",
   "metadata": {},
   "source": [
    "### âœ… Solution\n",
    "<details>\n",
    "<summary>Click to expand solution</summary>\n",
    "\n",
    "```python\n",
    "filtered_tools = [\n",
    "    t for t in tools\n",
    "    if \"application\" in (t.description or \"\").lower() \n",
    "]\n",
    "\n",
    "print(f\"Filtered tools ({len(filtered_tools)}):\")\n",
    "for tool in filtered_tools:\n",
    "    print(f\"Tool: {tool.name}\")\n",
    "    print(tool)\n",
    "    print(\"------\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1244fd86",
   "metadata": {},
   "source": [
    "## Task 1.5: Connect to an LLM via AI Core\n",
    "\n",
    "Each MCP-based scenario always involves three players: \n",
    "- One or multiple MCP Servers \n",
    "- A Hosting app which connects to the MCP Servers and runs the AI Agents\n",
    "- An LLM which makes the tooling decisions and generates the final answers to user requests\n",
    "\n",
    "We will now add the LLM to the game in this task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1121016",
   "metadata": {},
   "source": [
    "#### Initialize AI Core and connect to LLM\n",
    "\n",
    "We start with loading the AI Core credentials and connecting to an LLM.\n",
    "\n",
    "**ðŸš§ Your task:** Check that all environment variables `AICORE_xxx` mentioned below are set in the [.env file](../../.env), then execute the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068c87e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.proxy.langchain import init_llm\n",
    "\n",
    "AICORE_CLIENT_ID = os.getenv(\"AICORE_CLIENT_ID\")\n",
    "AICORE_CLIENT_SECRET = os.getenv(\"AICORE_CLIENT_SECRET\")\n",
    "AICORE_RESOURCE_GROUP = os.getenv(\"AICORE_RESOURCE_GROUP\")\n",
    "AICORE_BASE_URL = f\"{os.getenv('AICORE_BASE_URL')}/v2/lm\"\n",
    "AICORE_AUTH_URL = f\"{os.getenv('AICORE_AUTH_URL')}/oauth/token\"\n",
    "\n",
    "# Check if all variables are set (non-empty)\n",
    "required_vars = [\n",
    "    ('AICORE_CLIENT_ID', AICORE_CLIENT_ID),\n",
    "    ('AICORE_CLIENT_SECRET', AICORE_CLIENT_SECRET),\n",
    "    ('AICORE_RESOURCE_GROUP', AICORE_RESOURCE_GROUP),\n",
    "    ('AICORE_BASE_URL', AICORE_BASE_URL),\n",
    "    ('AICORE_AUTH_URL', AICORE_BASE_URL),\n",
    "]\n",
    "missing = [name for name, val in required_vars if not val]\n",
    "if missing:\n",
    "    print(f\"Warning: The following AI Core environment variables are not set: {', '.join(missing)}\")\n",
    "else:\n",
    "    print(\"All required AI Core environment variables are set.\")\n",
    "\n",
    "# Connect to the LLM\n",
    "llm = init_llm(\"gpt-4.1\", max_tokens=32767)\n",
    "\n",
    "# Structured print of important LLM fields\n",
    "fields = [\n",
    "    ('model_name', getattr(llm, 'model_name', None)),\n",
    "    ('max_tokens', getattr(llm, 'max_tokens', None)),\n",
    "    ('temperature', getattr(llm, 'temperature', None)),\n",
    "]\n",
    "print(\"LLM Configuration\")\n",
    "for name, value in fields:\n",
    "    if value is not None:\n",
    "        print(f\"  {name}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a267fa",
   "metadata": {},
   "source": [
    "You should see confirmation that all environment variables are set and the configuration of the LLM we connected to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82369bbd",
   "metadata": {},
   "source": [
    "#### Test the LLM\n",
    "\n",
    "We now need to test if the LLM works as expected.\n",
    "\n",
    "**ðŸš§ Your task:** Define a test prompt. Then execute the cell. \n",
    "\n",
    "Bonus task: Extract token usage from the response metadata. We added some debug output to make this task easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55e8bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "import pprint\n",
    "\n",
    "# TODO: ðŸš§ Write a test prompt of your choice - you can write anything you want\n",
    "test_prompt = \"\"\n",
    "response = llm.invoke(test_prompt)\n",
    "\n",
    "# Print the output as Markdown\n",
    "display(Markdown(f\"**LLM Response:**\\n\\n{response.content}\"))\n",
    "\n",
    "# Debug print the full response object to understand its structure\n",
    "pprint.pprint(\"Use this structure to find the right total tokens field\")\n",
    "pprint.pprint(f\"debug string: {response}\")\n",
    "\n",
    "# TODO: Bonus ðŸš§ Extract the number of tokens used from the response metadata\n",
    "# total_tokens = \n",
    "# display(Markdown(f\"`Total tokens used: {total_tokens}`\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614d7383",
   "metadata": {},
   "source": [
    "### âœ… Solution\n",
    "\n",
    "<details>\n",
    "<summary>Click to expand solution</summary>\n",
    "\n",
    "```python\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "response = llm.invoke(\"Hello world\")\n",
    "\n",
    "# Print the main response content as Markdown\n",
    "display(Markdown(f\"**LLM Response:**\\n\\n{response.content}\"))\n",
    "\n",
    "# Print the token usage in a highlighted way\n",
    "total_tokens = response.response_metadata[\"token_usage\"][\"total_tokens\"]\n",
    "display(Markdown(f\"`Total tokens used: {total_tokens}`\"))\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8ea35f",
   "metadata": {},
   "source": [
    "## Task 1.6: Create AI Agent\n",
    "\n",
    "Now we want to tackle the 3rd player of the MCP scenario and create an AI Agent that exposes MCP tools to an LLM to answer questions. We use a ReAct Agent from the LangGraph library for this purpose.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81128b13",
   "metadata": {},
   "source": [
    "#### Understanding ReAct Agents\n",
    "\n",
    "A **ReAct agent** (Reason + Act) is an AI agent that can both reason about problems and take actions using external tools. In LangGraph, a ReAct agent can:\n",
    "\n",
    "- Think step-by-step about a user's question\n",
    "- Decide when to use a tool (like searching in LeanIX)\n",
    "- Combine information from multiple sources\n",
    "- Respond in a way that's easy for employees to understand\n",
    "\n",
    "The agent acts as a knowledgeable guide that knows how to look up information and explain it clearly to internal users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba71b92",
   "metadata": {},
   "source": [
    "#### Initialize AI Agent\n",
    "\n",
    "We define the a LangGraph ReAct Agent with the cell below. \n",
    "\n",
    "**ðŸš§ Your task:** Run the cell below to create the Agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb0540a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from IPython.display import Markdown, display, Image \n",
    "\n",
    "agent =  create_react_agent(llm, filtered_tools)\n",
    "print(f\"Initialized Agent: {agent}\")\n",
    "\n",
    "async def call_agent(agent, query):\n",
    "    response = await agent.ainvoke(\n",
    "        {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": query}\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def print_agent_response(response):\n",
    "    msgs = response.get(\"messages\", [])\n",
    "    for msg in reversed(msgs):\n",
    "        content = getattr(msg, \"content\", \"\")\n",
    "        if content:\n",
    "            display(Markdown(content))\n",
    "            break\n",
    "    else:\n",
    "        print(\"No printable content in agent response.\")\n",
    "\n",
    "\n",
    "display(Image(agent.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16eab8c1",
   "metadata": {},
   "source": [
    "You can see the structure of the Agent in the graph. It's a simple loop deciding on tools and calling tools until the Agent thinks it has reached its goal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e195a535",
   "metadata": {},
   "source": [
    "#### Call the Agent\n",
    "\n",
    "Now we want the Agent to answer our Enterprise Architecture question. \n",
    "\n",
    "**ðŸš§ Your task:** Change the question below to the question we defined in the beginning of this exercise. Then execute the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4075fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"What is the weather like today?\"\n",
    "\n",
    "response = await call_agent(\n",
    "    agent, \n",
    "    user_question\n",
    ")\n",
    "print_agent_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aaeb029",
   "metadata": {},
   "source": [
    "You should now see the same list of 10 applications that we got in the LeanIX application in Task 1.1.\n",
    "\n",
    "You can further play around with other questions, also trying to be less precise with your ask and see if the AI Agent is able to handle it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6821f01",
   "metadata": {},
   "source": [
    "### âœ… Solution\n",
    "<details>\n",
    "<summary>Click to expand solution</summary>\n",
    "\n",
    "```python\n",
    "response = await call_agent(\n",
    "    agent, \n",
    "    \"Which applications have a perfect functional fit and fully appropriate technical fit?\"\n",
    ")\n",
    "print_agent_response(response)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2812441",
   "metadata": {},
   "source": [
    "Congratulations! You have successfully mastered this exercise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
