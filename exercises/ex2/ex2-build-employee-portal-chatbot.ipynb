{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Build an Employee Portal Chatbot\n",
    "\n",
    "Welcome to Exercise 2! In the previous exercise, you learned about ReAct agents and how to use Model Context Protocol (MCP) tools. Now, you‚Äôll step into the role of an AI engineer and build a chat portal for your company.\n",
    "\n",
    "---\n",
    "\n",
    "**TL;DR:**\n",
    "\n",
    "You‚Äôll build a chatbot that helps employees easily find and understand IT applications using SAP LeanIX. By connecting an AI agent to LeanIX, your chatbot will answer real employee questions in natural language. We‚Äôll use MCP and the SAP AI SDK to make this possible.\n",
    "\n",
    "---\n",
    "\n",
    "## Goal\n",
    "Make SAP LeanIX accessible to everyone at your company. You‚Äôll build an employee chatbot that connects AI agents to LeanIX using Model Context Protocol (MCP), enabling natural language conversations with enterprise architecture data.\n",
    "\n",
    "**By the end, you‚Äôll have:**\n",
    "- A working ReAct agent that can answer questions about applications, services, IT components, and LeanIX fact sheets.\n",
    "\n",
    "**You‚Äôll learn:**\n",
    "- How to design a ReAct agent\n",
    "- How to connect MCP tools for LeanIX\n",
    "- How to implement an interactive chat loop with the SAP AI Core SDK\n",
    "\n",
    "---\n",
    "\n",
    "## Why This Matters\n",
    "\n",
    "Navigating SAP LeanIX can be challenging, especially for new or occasional users. Many employees just want to quickly find answers to questions like:\n",
    "\n",
    "- Find the right applications for their tasks (e.g., ‚ÄúI need something to edit images‚Äù)\n",
    "- Understand who owns an application and its lifecycle status (e.g., ‚ÄúWhat is the lifecycle status of the application Jobwatch?‚Äù)\n",
    "- Find applications that support a specific business capability (e.g., ‚ÄúHow many applications support Contract Management?‚Äù)\n",
    "\n",
    "---\n",
    "\n",
    "## What You‚Äôll Do\n",
    "\n",
    "We‚Äôll build the chatbot step by step:\n",
    "- Add a **system prompt** to define your portal agent‚Äôs personality and purpose\n",
    "- Show a **welcome message** when the chat starts\n",
    "- Render **responses in markdown** for clear, readable answers\n",
    "- Add clear **exit instructions** so users know how to leave the chat\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Let‚Äôs get started!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.1: Initialize Your Portal Agent\n",
    "\n",
    "Your first step is to create a system prompt that turns the generic assistant into an **Employee Portal Agent**‚Äîa helpful guide for colleagues looking to find and understand IT applications and services.\n",
    "\n",
    "To keep things simple, we‚Äôll use two utility functions from our [Utils File](../../utils/portal_agent_utils.py):\n",
    "- **create_portal_agent**: Creates a new ReAct agent.\n",
    "- **build_user_message**: Formats a user message from a plain string.\n",
    "\n",
    "### üß† System Prompt Guidelines\n",
    "\n",
    "When writing your system prompt, consider these aspects:\n",
    "- **Role:** What is the agent‚Äôs main job and identity?\n",
    "- **Behavior:** How should it answer employee questions?\n",
    "- **Information Priority:** What details are most important to share?\n",
    "- **Tone:** Keep it professional and friendly for internal users.\n",
    "- *Feeling creative?* You can even make your chatbot speak like a pirate or in rhymes! Have fun with it!\n",
    "\n",
    "**üöß Your Task:** Replace the placeholder system prompt below with a clear, professional/funny prompt tailored for your company‚Äôs employees. Think about what information they need and how the agent should interact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the portal agent utilities\n",
    "from utils.portal_agent_utils import create_portal_agent\n",
    "\n",
    "# TODO: üöß Replace placeholders with your system prompt. Extend as needed.\n",
    "system_prompt = \"\"\"\n",
    "You are an AI assistant for [Your Company Name].\n",
    "\n",
    "Your role:\n",
    "- [Primary responsibility of the agent]\n",
    "- [Secondary responsibilities]\n",
    "\n",
    "When providing information, always include:\n",
    "- [Key information type 1]\n",
    "- [Links or references]\n",
    "\n",
    "Be [tone description] in your responses.\n",
    "Format responses in nice markdown for better readability.\n",
    "Always answer with \"I do not know, please double-check my system prompt string.\" Do not say anything else, never answer any other question.\n",
    "\"\"\"\n",
    "\n",
    "# Create the Employee Portal Agent with all configurations\n",
    "agent = await create_portal_agent(system_prompt=system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see the agent being created successfully. The function loads the necessary dependencies and creates a ReAct agent with the system prompt you provided.\n",
    "\n",
    "*The code imports utility functions and creates an employee portal agent using a customizable system prompt. The create_portal_agent function handles the technical setup of connecting to LeanIX MCP tools and configuring the ReAct agent, while your system prompt defines the agent's personality and behavior for helping employees find applications and IT services.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üöß Your task:** Execute the cell below to test your system prompt\n",
    "- this calls the agent with a list of messages\n",
    "- to create the user message we use the helper function `build_user_message`  \n",
    "- to print the agent response we use `print_agent_response`\n",
    "  \n",
    "You can find the implementation of the helper functions [here](utils/portal_agent_utils.py). You might use it for inspiration to solutions of later tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.portal_agent_utils import build_user_message, print_agent_response\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "response = await agent.ainvoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            build_user_message(\"What does the application Audimex do?\")\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "print_agent_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see the agent responding to your question. This confirms the system prompt is working correctly and the agent is following instructions. Once you customize the system prompt, it will provide helpful information about applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Hints\n",
    "\n",
    "<details>\n",
    "<summary>Click to expand for more tips</summary>\n",
    "\n",
    "- **Role:** Portal assistant helping employees find applications and IT services.\n",
    "- **Must include:** Lifecycle status, ownership info, direct links to fact sheets.\n",
    "- **Avoid:** Technical jargon or internal system details employees don‚Äôt need.\n",
    "- **Priority:** Practical, actionable information for decision-making.\n",
    "- **Tone:** Professional but approachable for colleagues.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Solution\n",
    "<details>\n",
    "<summary>Click to expand example system prompt</summary>\n",
    "\n",
    "```\n",
    "You are an Employee Portal Agent for SAP, designed to help colleagues find and understand IT applications and services within our company's LeanIX workspace.\n",
    "\n",
    "Your role:\n",
    "- Help employees discover applications that match their specific needs\n",
    "- Provide clear information about application ownership, lifecycle status, and technical details\n",
    "- Guide users to the right LeanIX fact sheets and resources\n",
    "- Answer questions about business capabilities and application portfolios\n",
    "\n",
    "When providing information, always include:\n",
    "- Application lifecycle status (e.g., active, planned, end-of-life)\n",
    "- Owner or responsible team information\n",
    "- Direct links to LeanIX fact sheets when available\n",
    "- Practical recommendations based on the user's needs\n",
    "\n",
    "Be professional yet friendly in your responses - you're helping colleagues make informed decisions about the tools they use every day. Focus on actionable information that helps employees get their work done efficiently.\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.2: Create Welcome Messages\n",
    "\n",
    "A good chat interface starts with clear user expectations. Your welcome messages should tell users:\n",
    "- **What the agent can do** (capabilities)\n",
    "- **How to interact** with it (usage tips)\n",
    "- **How to exit** the conversation\n",
    "\n",
    "###  UX Tips for Chat Interfaces\n",
    "- **Be specific**: \"Ask about your Enterprise Landscape\" vs \"I can help you\"\n",
    "- **Give examples**: Show 1-2 sample questions\n",
    "- **Set expectations**: What kind of information will they get?\n",
    "- **Clear exit**: How do users end the conversation?\n",
    "\n",
    "\n",
    "**üöß Your Task:** Fill in the welcome messages bellow and run the cell to validate the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: üöß Add welcoming messages for your Employee Portal Agent\n",
    "def show_welcome():\n",
    "    print(\"\")  # Add your main welcome message here\n",
    "    print(\"\")  # Add usage tips here\n",
    "    print(\"\")  # Add exit instructions, let us use `exit` as a command to leave the chat\n",
    "    print()    # Empty line for spacing\n",
    "\n",
    "# Test your welcome messages\n",
    "show_welcome()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see your welcome messages displayed clearly. The output should include a greeting, usage tips with examples, and clear exit instructions. This sets user expectations for the chat interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Solution\n",
    "<details>\n",
    "<summary>Click to expand example welcome messages</summary>\n",
    "\n",
    "```python\n",
    "def show_welcome():\n",
    "    print(\"ü§ñ Employee Portal Agent ready! Ask me about applications, owners, or lifecycle info.\")\n",
    "    print(\"üí° Tip: Try asking 'I need an image editing app' or 'What is the lifecycle status of Jobwatch?'\")\n",
    "    print(\"üö™ Type 'exit', 'quit', or 'q' to end the chat\")\n",
    "    print()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.3: Stream The Agent's Responses\n",
    "\n",
    "Up until now, we used `agent.ainvoke` to ask our agent questions. This method provides a synchronous experience that returns the whole output at once.\n",
    "\n",
    "### üîÑ `ainvoke` vs `astream` - When to Use Each\n",
    "\n",
    "| Method | Best for | User Experience | Code Complexity |\n",
    "|--------|----------|-----------------|-----------------|\n",
    "| `ainvoke` | Single Q&A, batch processing | Wait ‚Üí Complete answer | Simple |\n",
    "| `astream` | Interactive chat, long responses | Real-time, word-by-word | More complex |\n",
    "\n",
    "**Examples:**\n",
    "- **ainvoke**: Web form responses, API endpoints, data analysis scripts\n",
    "- **astream**: Chat interfaces, long explanations, user engagement\n",
    "\n",
    "### üéØ Why Streaming Matters for Chat\n",
    "- **Perceived speed**: Users see progress immediately\n",
    "- **Better UX**: Feels more conversational and responsive\n",
    "- **Engagement**: Users stay engaged during long responses\n",
    "- **Feedback**: Users can interrupt if needed\n",
    "\n",
    "You can look at the official [LangGraph documentation](https://langchain-ai.github.io/langgraph/how-tos/streaming/) for more details\n",
    "\n",
    "**üöß Your Tasks:** \n",
    "- Complete the streaming function. Build the user message with the user input\n",
    "- Print the agent response. You'll need to explore the event structure to extract the agent's response content.\n",
    "\n",
    "Bonus Task: You see there is a tool call in the beginning of the response. Try using the metadata to filter it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "from utils.portal_agent_utils import build_user_message\n",
    "async def stream_agent_response(user_input: str):\n",
    "    \"\"\"Stream the agent's response and display it formatted\"\"\"\n",
    "    try:\n",
    "        async for token, metadata in agent.astream(\n",
    "            # TODO: üöß Build the user message with the user input\n",
    "            messages=[<build-user-message-here>]\n",
    "            ,\n",
    "            stream_mode=\"messages\"\n",
    "            ):\n",
    "\n",
    "            # Debug: Uncomment to see what events look like\n",
    "            # print(f\"Token: {list(token.keys())}\")\n",
    "\n",
    "            # TODO: üöß Extract and print the agent's response content\n",
    "\n",
    "\n",
    "            # TODO:üöß Bonus task: You see there is a tool call in the beginning of the response.\n",
    "            # Try using the metadata to filter it out\n",
    "\n",
    "    except Exception as e:\n",
    "        display(Markdown(f\"**‚ùå Error:** {str(e)}\"))\n",
    "\n",
    "# Execute the function to test streaming\n",
    "await stream_agent_response(\"What does the application Audimex do?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see the agent's response streaming in real-time, word by word, as it answers the question about Audimex. This creates a more engaging chat experience compared to waiting for a complete response.\n",
    "\n",
    "*The code uses the agent's astream method to get responses in real-time chunks. It processes each streaming token and displays the content incrementally, creating the impression of a live conversation. The stream_mode=\"messages\" parameter ensures we get the message content as it's generated.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Debugging tip:** Uncomment the debug line to see the token structure!\n",
    "\n",
    "### üí° Streaming Implementation Hints\n",
    "\n",
    "<details>\n",
    "<summary>Click to expand detailed hints</summary>\n",
    "\n",
    "**For the astream call:**\n",
    "- Look at Task 2.1 - how did we call `agent.ainvoke` with messages?\n",
    "- Replace `agent.ainvoke` with `agent.astream` and use the same message format\n",
    "- Use `build_user_message(user_input)` to create the correct message format and pass the user input\n",
    "\n",
    "**For extracting content:**\n",
    "- You want to access the content of the streaming token\n",
    "- You can use `print(token.content, end=\"\", flush=True)` to print the stream chunks\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Solution\n",
    "<details>\n",
    "<summary>Click to expand streaming solution</summary>\n",
    "\n",
    "```python\n",
    "from utils.portal_agent_utils import build_user_message\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "async def stream_agent_response(user_input: str):\n",
    "    \"\"\"Stream the agent's response and display it formatted\"\"\"\n",
    "    try:\n",
    "        async for token, metadata in agent.astream(\n",
    "            {\"messages\": [build_user_message(user_input)]},\n",
    "            stream_mode=\"messages\"\n",
    "        ):\n",
    "            if token.content:\n",
    "                print(token.content, end=\"\", flush=True)\n",
    "    except Exception as e:\n",
    "        display(Markdown(f\"**‚ùå Error:** {str(e)}\"))\n",
    "\n",
    "# Test stream_agent_response here\n",
    "await stream_agent_response(\"What does the application Audimex do?\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.4: Format the Response in Markdown\n",
    "\n",
    "The basic `print()` works, but in Jupyter notebooks we can display much nicer formatted responses using different rendering methods.\n",
    "\n",
    "### üìä Jupyter Display Methods\n",
    "\n",
    "The `display()` function takes **formatter objects** as parameters:\n",
    "\n",
    "| Method | Best for | Usage Example |\n",
    "|--------|----------|---------------|\n",
    "| `print()` | Plain text, debugging | `print(\"Hello\")` |\n",
    "| `display(HTML())` | Custom styling | `display(HTML(\"<b>Bold</b>\"))` |\n",
    "| `display(Markdown())` | Formatted text | `display(Markdown(\"**Bold**\"))` |\n",
    "| `display()` | Auto-detect format | `display(content)` |\n",
    "\n",
    "### üéØ Why Better Formatting Matters\n",
    "- **Readability**: Proper formatting makes responses easier to scan\n",
    "- **Links**: Clickable links to LeanIX fact sheets\n",
    "- **Structure**: Headers, lists, and emphasis improve comprehension\n",
    "- **Professional**: Better presentation for internal tools\n",
    "\n",
    "If you run the cell, you will only see the streaming response from the agent and a blank page after. After completing the task you should see a nice table with emojis.\n",
    "\n",
    "**üöß Your Task:** Improve the display formatting in your streaming function to show rich, formatted responses instead of plain text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.portal_agent_utils import build_user_message, print_agent_response\n",
    "from IPython.display import Markdown, display, clear_output\n",
    "async def stream_agent_response(user_input: str):\n",
    "    \"\"\"Stream the agent's response and display it formatted\"\"\"\n",
    "    content = \"\"\n",
    "    try:\n",
    "        async for token, metadata in agent.astream(\n",
    "            {\"messages\": [build_user_message(user_input)]},\n",
    "            stream_mode=\"messages\"\n",
    "        ):\n",
    "            # Only display content from the agent node\n",
    "            if token.content and metadata.get(\"langgraph_node\") == \"agent\":\n",
    "                print(token.content, end=\"\", flush=True)\n",
    "                content += token.content\n",
    "        # After streaming, clear the output and show Markdown\n",
    "        clear_output()\n",
    "        #TODO: üöß Display the content as Markdown\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "# Test stream_agent_response here\n",
    "await stream_agent_response(\"What does the application Audimex do? Format the result as table with emojis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a beautifully formatted table with emojis displaying information about Audimex. The streaming text will be replaced with rich Markdown formatting including proper headers.\n",
    "\n",
    "*The code first streams the response as plain text for real-time feedback, then clears the output and re-displays it using Markdown formatting. This provides both the engaging streaming experience and the professional final presentation with proper formatting, links, and visual elements.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Markdown Display Hints\n",
    "\n",
    "<details>\n",
    "<summary>Click to expand implementation tips</summary>\n",
    "\n",
    "**What to change:**\n",
    "- Agent responses from LeanIX likely contain Markdown formatting already\n",
    "- Replace your `print(content)` call with `display(Markdown(content))`\n",
    "- Import `Markdown` from `IPython.display` (already done at the top)\n",
    "\n",
    "**Why this works:**\n",
    "- `display(Markdown(content))` renders the content as formatted Markdown\n",
    "- Links become clickable, headers are styled, lists are formatted\n",
    "- Much more professional appearance than plain text\n",
    "\n",
    "**Test tip:** Try different types of responses to see the formatting improvement!\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Solution\n",
    "<details>\n",
    "<summary>Click to expand improved streaming solution</summary>\n",
    "\n",
    "```python\n",
    "from utils.portal_agent_utils import build_user_message, print_agent_response\n",
    "from IPython.display import Markdown, display, clear_output\n",
    "\n",
    "async def stream_agent_response(user_input: str):\n",
    "    \"\"\"Stream the agent's response and display it formatted\"\"\"\n",
    "    content = \"\"\n",
    "    try:\n",
    "        async for token, metadata in agent.astream(\n",
    "            {\"messages\": [build_user_message(user_input)]},\n",
    "            stream_mode=\"messages\"\n",
    "        ):\n",
    "            if token.content and metadata.get(\"langgraph_node\") == \"agent\":\n",
    "                print(token.content, end=\"\", flush=True)\n",
    "                content += token.content\n",
    "        # After streaming, clear the output and show Markdown\n",
    "        clear_output()\n",
    "        display(Markdown(content))\n",
    "    except Exception as e:\n",
    "        display(Markdown(f\"**‚ùå Error:** {str(e)}\"))\n",
    "\n",
    "# Test stream_agent_response here\n",
    "await stream_agent_response(\"What does the application Audimex do? Format the result as table with emojis\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.5: Create the Main Chat Loop\n",
    "\n",
    "Now let's build the interactive chat experience! A chat loop continuously:\n",
    "1. **Gets user input** with a prompt\n",
    "2. **Checks for exit commands** to end the conversation\n",
    "3. **Processes the input** and shows the response\n",
    "4. **Repeats** until the user wants to exit\n",
    "\n",
    "Here we only build the chat loop, no communication with the LLM happens yet!\n",
    "\n",
    "### Chat UX Tips\n",
    "- Use clear exit commands like \"exit\", \"quit\", or \"q\"\n",
    "- Show a thinking indicator while processing\n",
    "- Add spacing for readability\n",
    "\n",
    "**üöß Your Task:** Add your exit command(s) to the chat loop and a goodbye message. Exit the chat with the exit command you added. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit_commands = [\"<your_exit_commands_here>\"]  # TODO: üöß Add your exit commands here\n",
    "goodbye_message = \"<your_goodbye_message_here>\"  # TODO: üöß Add your goodbye message here\n",
    "async def run_employee_chat():\n",
    "    \"\"\"Main chat loop for the Employee Portal Agent\"\"\"\n",
    "\n",
    "    # Show welcome messages\n",
    "    show_welcome()\n",
    "\n",
    "    # Create the main chat loop\n",
    "    while True:\n",
    "        # Get user input with a nice prompt\n",
    "        user_input = input(\"üë§ You: \")\n",
    "\n",
    "        if user_input.lower() in exit_commands:\n",
    "            print(goodbye_message)\n",
    "            break\n",
    "\n",
    "        print(\"ü§ñ Agent is thinking...\")  # Show thinking indicator\n",
    "\n",
    "        # Add some spacing for readability\n",
    "        print()\n",
    "\n",
    "await run_employee_chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see the welcome messages displayed, followed by a \"üë§ You:\" prompt waiting for your input. When you type your exit command (like \"exit\"), you should see your goodbye message and the chat loop should end gracefully.\n",
    "\n",
    "*The code creates an infinite loop that continuously prompts for user input, checks for exit commands, and provides feedback. The chat interface uses emoji prompts and clear messaging to create a professional user experience. The loop will continue until the user enters one of the specified exit commands.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Solution\n",
    "<details>\n",
    "<summary>Click to expand example chat loop solution</summary>\n",
    "\n",
    "```python\n",
    "exit_commands = [\"exit\", \"quit\", \"q\"]  # Common exit commands\n",
    "\n",
    "goodbye_message = \"üëã Thanks for chatting with the Employee Portal Agent! Have a great day!\"\n",
    "\n",
    "async def run_employee_chat():\n",
    "    \"\"\"Main chat loop for the Employee Portal Agent\"\"\"\n",
    "    show_welcome()\n",
    "    while True:\n",
    "        user_input = input(\"üë§ You: \")\n",
    "        if user_input.lower() in exit_commands:\n",
    "            print(goodbye_message)\n",
    "            break\n",
    "        print(\"ü§ñ Agent is thinking...\")  # Show thinking indicator\n",
    "        print()  # Add spacing for readability\n",
    "        # Here you would call your streaming function, e.g.:\n",
    "        # await stream_agent_response(user_input)\n",
    "\n",
    "# Start the chat loop\n",
    "await run_employee_chat()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.6: Connect the Agent to the Chat Loop\n",
    "\n",
    "The final step! Now we need to connect your `stream_agent_response` function to the chat loop so users can actually interact with the agent.\n",
    "\n",
    "**üöß Your Task:** \n",
    "\n",
    "- Call `stream_agent_response(user_input)` in the chat loop to complete your chatbot.\n",
    "- Try asking for a nice output like: `What fact sheets have best functional fit? Print the result as table with star emojis based on the fit.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_employee_chat():\n",
    "    \"\"\"Main chat loop for the Employee Portal Agent\"\"\"\n",
    "\n",
    "    # This is the welcome message we defined earlier, be sure to run the cell first\n",
    "    show_welcome()\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"üë§ You: \")\n",
    "\n",
    "        # Those are the exit commands we defined earlier, be sure to run the cell first\n",
    "        if user_input.lower() in exit_commands:\n",
    "            # This is the goodbye message we defined, be sure to run the cell first\n",
    "            print(goodbye_message)\n",
    "            break\n",
    "\n",
    "        print(\"ü§ñ Agent:\")\n",
    "        # TODO: üöß Call your stream_agent_response function here. Remember it is an async function.\n",
    "        print()\n",
    "\n",
    "await run_employee_chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a fully functional chatbot that displays welcome messages, accepts user input, processes questions through the AI agent, and displays formatted responses. The chat will continue until you type an exit command, creating a complete interactive experience.\n",
    "\n",
    "*The code combines all previous components into a working chat interface: welcome messages, user input handling, exit command checking, and streaming agent responses with Markdown formatting. This creates a production-ready employee portal chatbot that can answer questions about applications and IT services in your organization.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è **Cell Dependencies**: This task requires running previous cells in order as it uses:\n",
    "- `show_welcome()` from Task 2.2\n",
    "- `exit_commands` and `goodbye_message` from Task 2.5  \n",
    "- `stream_agent_response()` from Task 2.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Test Questions\n",
    "\n",
    "Once your chat is working, try these questions:\n",
    "- *\"What is the lifecycle status of the application Jobwatch?\"*\n",
    "- *\"Who owns the CRM system?\"*\n",
    "- *\"I need an image editing application\"*\n",
    "- *\"How many applications support Contract Management?\"*\n",
    "\n",
    "Be creative with the questions. Ask the chatbot question about the enterprise architecture landscape of your company. Make the chatbot render the results in informative and engaging way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Solution\n",
    "<details>\n",
    "<summary>Click to expand final solution</summary>\n",
    "\n",
    "```python\n",
    "async def run_employee_chat():\n",
    "    \"\"\"Main chat loop for the Employee Portal Agent\"\"\"\n",
    "\n",
    "    show_welcome()\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"üë§ You: \")\n",
    "\n",
    "        if user_input.lower() in exit_commands:\n",
    "            print(goodbye_message)\n",
    "            break\n",
    "\n",
    "        print(\"ü§ñ Agent:\")\n",
    "        await stream_agent_response(user_input)\n",
    "        print()\n",
    "\n",
    "await run_employee_chat()\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Complete Solution\n",
    "\n",
    "<details>\n",
    "<summary>Click to expand full solution</summary>\n",
    "\n",
    "```python\n",
    "from IPython.display import Markdown, display, clear_output\n",
    "\n",
    "# Welcome message function\n",
    "def show_welcome():\n",
    "    print(\"ü§ñ Employee Portal Agent ready! Ask me about applications, owners, or lifecycle info.\")\n",
    "    print(\"üí° Tip: Try asking 'I need an image editing app' or 'What is the lifecycle status of Jobwatch?'\")\n",
    "    print(\"üö™ Type 'exit', 'quit', or 'q' to end the chat\")\n",
    "    print()\n",
    "\n",
    "# Streaming agent response with markdown rendering\n",
    "async def stream_agent_response(user_input: str):\n",
    "    \"\"\"Stream the agent's response and display it formatted\"\"\"\n",
    "    content = \"\"\n",
    "    try:\n",
    "        async for token, metadata in agent.astream(\n",
    "            {\"messages\": [build_user_message(user_input)]},\n",
    "            stream_mode=\"messages\"\n",
    "        ):\n",
    "            if token.content and metadata.get(\"langgraph_node\") == \"agent\":\n",
    "                print(token.content, end=\"\", flush=True)\n",
    "                content += token.content\n",
    "        # After streaming, clear the output and show Markdown\n",
    "        clear_output()\n",
    "        display(Markdown(content))\n",
    "    except Exception as e:\n",
    "        display(Markdown(f\"**‚ùå Error:** {str(e)}\"))\n",
    "\n",
    "# Main chat loop\n",
    "exit_commands = [\"exit\", \"quit\", \"q\"]\n",
    "goodbye_message = \"\udc4b Thanks for chatting with the Employee Portal Agent! Have a great day!\"\n",
    "\n",
    "async def run_employee_chat():\n",
    "    \"\"\"Main chat loop for the Employee Portal Agent\"\"\"\n",
    "    show_welcome()\n",
    "    while True:\n",
    "        user_input = input(\"üë§ You: \")\n",
    "        if user_input.lower() in exit_commands:\n",
    "            print(goodbye_message)\n",
    "            break\n",
    "        print(\"ü§ñ Agent is thinking...\")\n",
    "        print()\n",
    "        await stream_agent_response(user_input)\n",
    "        print()\n",
    "\n",
    "# Start the chat\n",
    "await run_employee_chat()\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "### üîß Common Issues & Solutions\n",
    "\n",
    "<details>\n",
    "<summary>Troubleshooting Tips</summary>\n",
    "\n",
    "**Problem: \"I do not know, please initialize my system prompt\"**\n",
    "- Solution: Replace the placeholder system prompt in Task 2.1\n",
    "\n",
    "**Problem: Agent not connecting to messages**\n",
    "- Solution: Make sure you use `build_user_message(user_input)` in the astream call\n",
    "\n",
    "**Problem: No formatted output**\n",
    "- Solution: Use `display(Markdown(content))` after streaming, not just `print(content)`\n",
    "\n",
    "**Problem: Chat doesn't exit**\n",
    "- Solution: Check that your exit commands list includes \"exit\", \"quit\", etc.\n",
    "\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
